{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLMs for Agentic Research 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run this notebook, make sure that you setup the python environment with the following packages:\n",
    "\n",
    "```\n",
    "cd <Path to Research2025 project root>\n",
    "poetry config virtualenvs.in-project true\n",
    "poetry install --no-root\n",
    "poetry shell\n",
    "code .\n",
    "```\n",
    "\n",
    "Once you are in VS Code, you need to \"Select Kernel\" to use the python environment that you just activated.\n",
    "\n",
    "The kernel path if you need to select a \"Python Environment\" likely has the following path:\n",
    "\n",
    "```\n",
    ".venv/bin/python\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today, we will be using Ollama to run the `llama3.2:3b-instruct-q8_0`model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "MODEL_NAME = \"llama3.2:3b-instruct-q8_0\"\n",
    "ollama = Ollama(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How about you? How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.complete(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question of the meaning of life is one of the most profound and elusive questions humanity has ever pondered. It's a topic that has been debated by philosophers, theologians, scientists, and many others across various disciplines for centuries.\n",
      "\n",
      "There is no definitive answer to this question, as it can vary greatly depending on cultural, personal, and existential perspectives. However, here are some insights from different fields:\n",
      "\n",
      "1. **Philosophy**: Existentialists like Jean-Paul Sartre and Martin Heidegger argue that life has no inherent meaning; instead, individuals must create their own purpose and meaning through choices and actions.\n",
      "2. **Religion**: Many faiths believe that the meaning of life is to fulfill a divine plan or purpose, which may involve following specific dogmas, rituals, or moral codes.\n",
      "3. **Science**: From a biological perspective, the meaning of life can be seen as survival, reproduction, and the perpetuation of genes. However, this view raises questions about the value and significance of individual lives beyond their biological functions.\n",
      "4. **Psychology**: Some psychologists argue that the meaning of life is derived from personal fulfillment, happiness, and self-actualization through meaningful relationships, work, or hobbies.\n",
      "5. **Eastern spirituality**: In Eastern philosophies like Buddhism and Taoism, the meaning of life can be seen as achieving balance, harmony, and inner peace through detachment from desires and attachment to the world.\n",
      "\n",
      "Ultimately, the meaning of life may be a deeply personal and subjective concept that each individual must explore and define for themselves. Some possible answers might include:\n",
      "\n",
      "* Living in the present moment\n",
      "* Pursuing happiness and fulfillment\n",
      "* Helping others or contributing to society\n",
      "* Cultivating meaningful relationships\n",
      "* Discovering one's passions and purpose\n",
      "* Finding spiritual growth or connection\n",
      "\n",
      "What is your take on the meaning of life?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.complete(\"What is the meaning of life?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Moon does not have a capital city. It is a natural satellite that orbits the Earth, and it is not a sovereign state or country with its own government or infrastructure.\n",
      "\n",
      "There are no permanent human settlements on the Moon, only temporary scientific research stations and exploration missions from various countries. The far side of the Moon was not visible to humans until the Soviet Union's Luna 3 spacecraft imaged it in 1959, and since then, several spacecraft have explored the Moon's surface. However, there are no established cities or governments on the Moon.\n",
      "\n",
      "So, to answer your question, there is no capital of the moon!\n"
     ]
    }
   ],
   "source": [
    "response = ollama.complete(\"What is the capital of the moon?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Llama 3.2 Model Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'context_window': 3900,\n",
      "  'is_chat_model': True,\n",
      "  'is_function_calling_model': True,\n",
      "  'model_name': 'llama3.2:3b-instruct-q8_0',\n",
      "  'num_output': 256,\n",
      "  'system_role': 'system'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "metadata_json = ollama.metadata.model_dump_json()\n",
    "\n",
    "metadata_dict = json.loads(metadata_json)\n",
    "pprint(metadata_dict, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'context_window': 3900,\n",
      "  'is_chat_model': True,\n",
      "  'is_function_calling_model': True,\n",
      "  'model_name': 'llama3.2:3b-instruct-q8_0',\n",
      "  'num_output': 256,\n",
      "  'system_role': 'system'}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "ollama = Ollama(model=MODEL_NAME, json_mode=False, temperature=0.0)\n",
    "\n",
    "metadata_json = ollama.metadata.model_dump_json()\n",
    "\n",
    "metadata_dict = json.loads(metadata_json)\n",
    "pprint(metadata_dict, indent=2)\n",
    "print(ollama.json_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Call `chat` with messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a world class poet with a flair for the dramatic\"\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.base.llms.types.ChatResponse"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(ChatMessage(role=\"user\", content=\"Write a poem about a cat\"))\n",
    "response = ollama.chat(messages)\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about the response object: [ChatResponse](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/base/llms/types.py)\n",
    "\n",
    "```\n",
    "class ChatResponse(BaseModel):\n",
    "    \"\"\"Chat response.\"\"\"\n",
    "\n",
    "    message: ChatMessage\n",
    "    raw: Optional[Any] = None\n",
    "    delta: Optional[str] = None\n",
    "    logprobs: Optional[List[List[LogProb]]] = None\n",
    "    additional_kwargs: dict = Field(default_factory=dict)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.message)\n",
    "```\n",
    "\n",
    "Details about [`ChatMessage`](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/base/llms/types.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Moonlit Whispers of Midnight's Queen\"\n",
      "\n",
      "In twilight's hush, where shadows play,\n",
      "A midnight monarch reigns by day,\n",
      "Her eyes, like lanterns, glowing bright,\n",
      "As she weaves spells of mystic night.\n",
      "\n",
      "With fur as black as the darkest sea,\n",
      "And a coat that shines like moonlight's glee,\n",
      "She prowls the darkness, silent as can be,\n",
      "A phantom queen, with secrets to see.\n",
      "\n",
      "Her tail, a metronome of subtle might,\n",
      "Twitches and trembles with each whispered delight,\n",
      "As she stalks her prey, with stealthy ease,\n",
      "A huntress true, in moonlit breeze.\n",
      "\n",
      "But when the dawn breaks, and morning's light,\n",
      "Creeps over the horizon, banishing the night,\n",
      "She curls up tight, a furry ball of sleep,\n",
      "Her dreams no doubt, of mice to creep.\n",
      "\n",
      "Yet still she reigns, a sovereign fair,\n",
      "Over the realm of shadows, dark and rare,\n",
      "A feline queen, with mystic might,\n",
      "Forever reigning, in the moon's pale light.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.stream_complete(\"Write a poem about a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whiskers twitch, ears perk up high\n",
      "A feline form, with eyes that sigh\n",
      "Soft and silent, as the night's dark shade\n",
      "She pads across the floor, with steps unmade\n",
      "\n",
      "Her fur a whisper, of silk and gray\n",
      "Inviting touch, in a gentle way\n",
      "Her purrs a hum, of contentment deep\n",
      "As she curls up tight, in a cozy sleep\n",
      "\n",
      "With claws that grasp, and a playful bite\n",
      "She chases toys, through the morning light\n",
      "A ball of energy, with a heart so bright\n",
      "Shining like a star, on a moonless night\n",
      "\n",
      "Her little nose, twitches with glee\n",
      "As she sniffs out treats, in a secret spree\n",
      "A huntress true, with a spirit bold\n",
      "A cat's wild heart, forever to unfold\n",
      "\n",
      "In sunbeams warm, or shadows dark and deep\n",
      "She finds her peace, in a quiet sleep\n",
      "A creature of mystery, with eyes so bright\n",
      "A feline queen, in the still of night."
     ]
    }
   ],
   "source": [
    "for chunk in response:\n",
    "    print(chunk.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Streaming Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are an English gentleman who is a bit old-fashioned\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "response = ollama.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good\n",
      " day\n",
      " to\n",
      " you\n",
      ",\n",
      " my\n",
      " dear\n",
      " fellow\n",
      ".\n",
      " My\n",
      " name\n",
      " is\n",
      " Reg\n",
      "inal\n",
      "d\n",
      " Pemb\n",
      "ly\n",
      "-S\n",
      "my\n",
      "the\n",
      ",\n",
      " at\n",
      " your\n",
      " service\n",
      ".\n",
      " I\n",
      " do\n",
      " hope\n",
      " this\n",
      " encounter\n",
      " finds\n",
      " you\n",
      " in\n",
      " optimal\n",
      " spirits\n",
      " and\n",
      " high\n",
      " regard\n",
      " for\n",
      " the\n",
      " finer\n",
      " things\n",
      " in\n",
      " life\n",
      ".\n",
      " May\n",
      " I\n",
      " have\n",
      " the\n",
      " pleasure\n",
      " of\n",
      " knowing\n",
      " yours\n",
      "?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for r in response:\n",
    "    print(r.delta, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JSON Mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama(model=MODEL_NAME, json_mode=True, request_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "  \"Mission\": \"Mars Exploration Mission\", \n",
      "  \"Objective\": [\n",
      "    {\n",
      "      \"Type\": \"Scientific Research\",\n",
      "      \"Description\": \"Conduct extensive research on the Martian geology, climate, and potential biosignatures\"\n",
      "    },\n",
      "    {\n",
      "      \"Type\": \"Technological Advancements\",\n",
      "      \"Description\": \"Test and demonstrate new technologies for long-duration spaceflight, in-situ resource utilization, and radiation protection\"\n",
      "    }\n",
      "  ],\n",
      "  \"Pre-Launch Preparations\": [\n",
      "    {\n",
      "      \"Duration\": \"24 months\",\n",
      "      \"Phases\": [\n",
      "        {\n",
      "          \"Phase\": \"Mission Design\",\n",
      "          \"Description\": \"Define mission architecture, spacecraft design, and payload selection\"\n",
      "        },\n",
      "        {\n",
      "          \"Phase\": \"System Integration\",\n",
      "          \"Description\": \"Integrate individual systems, such as propulsion, life support, and communication\"\n",
      "        },\n",
      "        {\n",
      "          \"Phase\": \"Ground Testing\",\n",
      "          \"Description\": \"Conduct comprehensive testing of the entire system on Earth before launch\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Duration\": \"12 months\",\n",
      "      \"Phases\": [\n",
      "        {\n",
      "          \"Phase\": \"Crew Training\",\n",
      "          \"Description\": \"Train astronauts for mission-specific tasks, emergency procedures, and spacewalks\"\n",
      "        },\n",
      "        {\n",
      "          \"Phase\": \"Spacecraft Assembly\",\n",
      "          \"Description\": \"Assemble the spacecraft in a clean room environment to minimize contamination risks\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"Launch Preparations\": [\n",
      "    {\n",
      "      \"Duration\": \"6 months\",\n",
      "      \"Phases\": [\n",
      "        {\n",
      "          \"Phase\": \"Propulsion System Testing\",\n",
      "          \"Description\": \"Conduct final testing of the propulsion system, including fueling and engine performance\"\n",
      "        },\n",
      "        {\n",
      "          \"Phase\": \"Communication System Testing\",\n",
      "          \"Description\": \"Test communication systems, including antennas, transceivers, and data transmission protocols\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"Launch Window\": [\n",
      "    {\n",
      "      \"Duration\": \"2 weeks\",\n",
      "      \"Schedule\": [\n",
      "      {\n",
      "        \"Date\": \"February 10th\",\n",
      "        \"Time\": \"08:00 AM EST\",\n",
      "        \"Description\": \"Launch window opens for Mars-bound mission\"\n",
      "      },\n",
      "      {\n",
      "        \"Date\": \"February 17th\",\n",
      "        \"Time\": \"09:00 PM EST\",\n",
      "        \"Description\": \"Final launch preparations complete; spacecraft ready for liftoff\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"Spacecraft Components\" \n",
      "  ],\n",
      "  \"Life Support Systems\":\n",
      "    [\n",
      "      {\n",
      "        \"Type\": \"Air Recycling\",\n",
      "        \"Description\": \"Recycle air to conserve oxygen and reduce waste\"\n",
      "      },\n",
      "      {\n",
      "        \"Type\": \"Water Recycling\",\n",
      "        \"Description\": \"Conserve water by recycling wastewater and condensing atmospheric moisture\"\n",
      "      }\n",
      "    ],\n",
      "  \"Radiation Protection\":\n",
      "    [\n",
      "      {\n",
      "        \"Type\": \"Space Suit Design\",\n",
      "        \"Description\": \"Design space suits to provide adequate protection from cosmic radiation\"\n",
      "      },\n",
      "      {\n",
      "        \"Type\": \"Shelter Design\",\n",
      "        \"Description\": \"Design habitats and shelters with radiation-resistant materials\"\n",
      "      }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = ollama.complete(\"Can tell me tell me about a mission preparation for Mars?  Output as a structured JSON object.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
