{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRM RAG Evaluation\n",
    "\n",
    "Author: Theodore Mui <thephilmui@gmail.com>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from llama_index.core import (\n",
    "    PromptTemplate,\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2:3b-instruct-q8_0\", temperature=0.01)\n",
    "embedding = OllamaEmbedding(model_name=\"mxbai-embed-large\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding\n",
    "\n",
    "hello_embedding = embedding.get_text_embedding(\"hello\")\n",
    "EMBEDDING_DIM = len(hello_embedding)\n",
    "print(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "notebook_dir = Path().absolute()\n",
    "\n",
    "crm_folder = str(notebook_dir / \"..\" / \"data\" / \"crm-docs\")\n",
    "LLAMA_CLOUD_API_KEY = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "len(LLAMA_CLOUD_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id c7b00490-7685-4ab4-8d17-bf4bde76c05f\n",
      "CPU times: user 80.7 ms, sys: 70.5 ms, total: 151 ms\n",
      "Wall time: 7.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# llama cloud ingestion\n",
    "parser = LlamaParse(\n",
    "    num_workers=6,\n",
    "    result_type=\"markdown\",\n",
    "    api_key=LLAMA_CLOUD_API_KEY\n",
    ")\n",
    "file_extractor = {\".pdf\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=crm_folder,\n",
    "    file_extractor=file_extractor\n",
    ").load_data(num_workers=10)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# Table of Contents\\n'\n",
      " '\\n'\n",
      " '# UNITED STATES\\n'\n",
      " '\\n'\n",
      " '# SECURITIES AND EXCHANGE COMMISSION\\n'\n",
      " '\\n'\n",
      " '# Washington, D.C. 20549')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(documents[0].text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creation_date': '2025-04-05',\n",
      " 'file_name': 'salesforce-fy24-10k.pdf',\n",
      " 'file_path': '/Users/pmui/SynologyDrive/research/2025/research2025/projects/advanced-rag/notebook/../data/crm-docs/salesforce-fy24-10k.pdf',\n",
      " 'file_size': 1516703,\n",
      " 'file_type': 'application/pdf',\n",
      " 'last_modified_date': '2025-04-05'}\n"
     ]
    }
   ],
   "source": [
    "pprint(documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Evaluation Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset import Testset\n",
    "\n",
    "folder_path = notebook_dir / \"..\" / \"data\" / \"crm-eval\"\n",
    "if not folder_path.exists():\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sdg_folder = str(folder_path)\n",
    "\n",
    "single_hop_specific_testset = Testset.from_jsonl(f\"{sdg_folder}/single_hop_specific_testset.jsonl\")\n",
    "multi_hop_specific_testset = Testset.from_jsonl(f\"{sdg_folder}/multi_hop_specific_testset.jsonl\")\n",
    "multi_hop_abstract_testset = Testset.from_jsonl(f\"{sdg_folder}/multi_hop_abstract_testset.jsonl\")\n",
    "\n",
    "single_hop_specific_list = single_hop_specific_testset.to_list()\n",
    "multi_hop_specific_list = multi_hop_specific_testset.to_list()\n",
    "multi_hop_abstract_list = multi_hop_abstract_testset.to_list()\n",
    "\n",
    "len(single_hop_specific_list), len(multi_hop_specific_list), len(multi_hop_abstract_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': 'How does Salesforce enhance customer relationship management for businesses?',\n",
       " 'reference_contexts': ['Overview Salesforce, Inc. (“Salesforce,” the “Company,” “we” or “our”) is a global leader in customer relationship management (“CRM”) technology, enabling companies of every size and industry to connect with their customers through the power of data, artificial intelligence (“AI”), CRM and trust. Founded in 1999, we bring humans together with AI agents to drive customer success on one deeply unified platform. Our AI-powered Salesforce Platform unites our offerings — spanning sales, service, marketing, commerce, collaboration, integration, AI, analytics, automation, industries and more — by connecting customer data across systems, applications and devices to create a complete view of customers. With this single source of customer truth, teams can be more responsive, productive and efficient and deliver intelligent, personalized and automated experiences across every channel. With Agentforce, the agentic layer of the Salesforce Platform, our customers can build and augment their teams with an always-on digital labor force, deploying autonomous AI agents across business functions that aim to increase productivity, lower costs and drive operational efficiencies. Our service offerings are designed to be flexible, scalable and easy to use. They can generally be configured easily, deployed rapidly and integrated with other platforms and enterprise applications. We sell to businesses worldwide, primarily on a subscription basis, through our direct sales efforts and also indirectly through partners. In addition, we enable third parties to use our platform and developer tools to create additional functionality and new applications that run on our platform, which are sold separately from, or in conjunction with, our service offerings. Salesforce is committed to a core set of values: trust, customer success, innovation, equality and sustainability – all of which are grounded in legal and regulatory frameworks that guide and inform our business. Foremost among these is trust, which is paramount and the foundation for everything we do, and is also firmly rooted in compliance with applicable laws governing security, privacy, data protection and operational integrity. Our customers expect to trust and rely on our technology to meet the high enterprise-grade standards of security, privacy, performance, legal compliance and availability at scale. Customer success is at the core of our business, and we align the entire company around our customers’ needs, promoting their success, showing our value and upholding applicable laws, contractual obligations and industry regulations and standards. Innovation is fundamental to our mission, empowering and enabling our customers to stay ahead in their industries and driving technological advancements in line with evolving laws, standards and guidelines. Equality is a legal and ethical mandate and a core tenet that informs how we operate. Our commitment to equal opportunity is anchored in applicable laws, statutes, regulations and principles. We value the equality of every individual at our company and in our communities and are dedicated to fostering a workplace that complies with these protections, creating an inclusive culture where every individual feels seen, heard and valued. Finally, we are committed to creating a more sustainable and nature-positive future for all. Our products and services help our customers meet their own sustainability and compliance priorities, guided by applicable environmental and sustainability-related laws, corporate social responsibility frameworks and legal requirements. By grounding our values in legal and regulatory principles, we reinforce our opportunity and responsibility to uphold high integrity and robust ethical standards, ensuring that trust, fairness, and compliance remain central to everything we seek to do. We believe that our values, grounded in legal and regulatory frameworks, create value, and the business of business is to make the world a better place for all of our stakeholders, including stockholders, customers, employees, partners, the planet and the communities in which we work and live. Salesforce is committed to giving back to our communities, helping businesses grow while protecting the environment for future generations, and transparent environmental, social and governance disclosures. We believe we have a broad responsibility to society, and we aspire to create a framework for the ethical and humane use of technology that not only drives the success of our customers, but also upholds the basic human rights of every individual. #'],\n",
       " 'reference': 'Salesforce enhances customer relationship management by enabling companies to connect with their customers through data, artificial intelligence, and a unified platform. It provides a complete view of customers by connecting customer data across systems, applications, and devices, allowing teams to be more responsive, productive, and efficient. Additionally, Salesforce offers flexible and scalable service offerings that can be easily configured, deployed, and integrated with other platforms, promoting customer success and innovation.',\n",
       " 'synthesizer_name': 'single_hop_specific'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_hop_specific_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Constructing RAG Engines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Creating Text Chunkers (\"Node Parsers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    TokenTextSplitter,\n",
    "    MarkdownNodeParser, MarkdownElementNodeParser,\n",
    "    SemanticSplitterNodeParser,\n",
    "    SentenceSplitter, \n",
    "    SentenceWindowNodeParser,\n",
    ")\n",
    "\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from typing import Callable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text_splitter = TokenTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=32,\n",
    ")\n",
    "\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=32,\n",
    ")\n",
    "\n",
    "md_node_parser = MarkdownNodeParser.from_defaults(\n",
    "    include_metadata=True,\n",
    "    include_prev_next_rel=True,\n",
    ")\n",
    "\n",
    "mde_node_parser = MarkdownElementNodeParser(\n",
    "    llm=llm,\n",
    "    num_workers=10,\n",
    ").from_defaults()\n",
    "\n",
    "semantic_splitter = SemanticSplitterNodeParser(\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Creating Indices & Query Engines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 155/155 [00:00<00:00, 233.21it/s]\n",
      "Generating embeddings: 100%|██████████| 183/183 [00:13<00:00, 13.56it/s]\n"
     ]
    }
   ],
   "source": [
    "token_text_splitter_index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    show_progress=True,\n",
    "    node_parser=token_text_splitter,\n",
    ")\n",
    "token_text_splitter_query_engine = token_text_splitter_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 155/155 [00:00<00:00, 2049.76it/s]\n",
      "Generating embeddings: 100%|██████████| 183/183 [00:12<00:00, 14.08it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_splitter_index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    show_progress=True,\n",
    "    node_parser=sentence_splitter,\n",
    "    num_workers=10,\n",
    ")\n",
    "sentence_splitter_query_engine = sentence_splitter_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 568/568 [00:23<00:00, 23.74it/s]\n"
     ]
    }
   ],
   "source": [
    "md_nodes = md_node_parser.get_nodes_from_documents(documents)\n",
    "md_index = VectorStoreIndex(\n",
    "    nodes=md_nodes, \n",
    "    show_progress=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "md_query_engine = md_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 50231.19it/s]\n",
      "1it [00:00, 12633.45it/s]\n",
      "1it [00:00, 17260.51it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 20460.02it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 15592.21it/s]\n",
      "1it [00:00, 26379.27it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 128659.63it/s]\n",
      "3it [00:00, 83886.08it/s]\n",
      "3it [00:00, 49932.19it/s]\n",
      "2it [00:00, 55188.21it/s]\n",
      "1it [00:00, 27776.85it/s]\n",
      "2it [00:00, 47662.55it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "2it [00:00, 47393.27it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 18157.16it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 16384.00it/s]\n",
      "3it [00:00, 61380.06it/s]\n",
      "1it [00:00, 13934.56it/s]\n",
      "1it [00:00, 25731.93it/s]\n",
      "1it [00:00, 12052.60it/s]\n",
      "1it [00:00, 39945.75it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 33288.13it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 24528.09it/s]\n",
      "2it [00:00, 39016.78it/s]\n",
      "4it [00:00, 72628.64it/s]\n",
      "3it [00:00, 57456.22it/s]\n",
      "2it [00:00, 33825.03it/s]\n",
      "1it [00:00, 26379.27it/s]\n",
      "3it [00:00, 48960.75it/s]\n",
      "2it [00:00, 44620.26it/s]\n",
      "2it [00:00, 7013.89it/s]\n",
      "2it [00:00, 33825.03it/s]\n",
      "3it [00:00, 87992.39it/s]\n",
      "2it [00:00, 32768.00it/s]\n",
      "2it [00:00, 31536.12it/s]\n",
      "3it [00:00, 60205.32it/s]\n",
      "3it [00:00, 6423.13it/s]\n",
      "3it [00:00, 50942.96it/s]\n",
      "1it [00:00, 26379.27it/s]\n",
      "2it [00:00, 33961.98it/s]\n",
      "1it [00:00, 18477.11it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 16980.99it/s]\n",
      "1it [00:00, 14665.40it/s]\n",
      "1it [00:00, 13357.66it/s]\n",
      "2it [00:00, 28149.69it/s]\n",
      "1it [00:00, 18558.87it/s]\n",
      "1it [00:00, 29537.35it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 29537.35it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 23831.27it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 11781.75it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 16194.22it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 19599.55it/s]\n",
      "1it [00:00, 19239.93it/s]\n",
      "1it [00:00, 9709.04it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial mde nodes: 426\n",
      "Number of text nodes: 244\n",
      "Number of table nodes: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 335/335 [00:16<00:00, 20.21it/s]\n"
     ]
    }
   ],
   "source": [
    "mde_nodes = mde_node_parser.get_nodes_from_documents(documents=documents, verbose=False)\n",
    "\n",
    "print(f\"Number of initial mde nodes: {len(mde_nodes)}\")\n",
    "\n",
    "# Get text nodes and object (table) nodes\n",
    "base_nodes, objects = mde_node_parser.get_nodes_and_objects(nodes=mde_nodes)\n",
    "\n",
    "print(f\"Number of text nodes: {len(base_nodes)}\")\n",
    "print(f\"Number of table nodes: {len(objects)}\")\n",
    "\n",
    "# insert the table markdown into the text of each table object\n",
    "for i in range(len(objects)):\n",
    "    objects[i].text = objects[i].text[:]\n",
    "\n",
    "mde_index = VectorStoreIndex(\n",
    "    nodes=base_nodes + objects,\n",
    "    show_progress=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "mde_query_engine = mde_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 358/358 [00:19<00:00, 18.47it/s]\n"
     ]
    }
   ],
   "source": [
    "semantic_nodes = semantic_splitter.get_nodes_from_documents(documents=documents)\n",
    "\n",
    "semantic_index = VectorStoreIndex(\n",
    "    nodes=semantic_nodes,\n",
    "    show_progress=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "semantic_query_engine = semantic_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating RAG Engines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate, EvaluationDataset\n",
    "from ragas.llms import LlamaIndexLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    AnswerAccuracy,\n",
    "    AnswerCorrectness,\n",
    "    AnswerRelevancy, \n",
    "    ContextRelevance,\n",
    "    ContextPrecision, \n",
    "    ContextRecall,\n",
    "    Faithfulness, \n",
    "    FactualCorrectness, \n",
    "    ResponseGroundedness, \n",
    "    ResponseRelevancy\n",
    ")\n",
    "\n",
    "evaluator_llm = LlamaIndexLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Single Hop Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Responding to queries: 100%|██████████| 100/100 [04:26<00:00,  2.66s/query]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 148 ms, total: 2.05 s\n",
      "Wall time: 4min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_queries = len(single_hop_specific_list)\n",
    "for test_case in tqdm(single_hop_specific_list, \n",
    "                      desc=\"Responding to queries\",\n",
    "                      total=total_queries,\n",
    "                      unit=\"query\",\n",
    "                      position=0,\n",
    "                      leave=True):\n",
    "    token_text_splitter_response = token_text_splitter_query_engine.query(test_case[\"user_input\"])\n",
    "    test_case[\"response\"] = str(token_text_splitter_response.response)\n",
    "    test_case[\"retrieved_contexts\"] = [node.text for node in token_text_splitter_response.source_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user_input': 'What CRM do Salesforce do?',\n",
       "  'reference_contexts': ['Overview Salesforce, Inc. (“Salesforce,” the “Company,” “we” or “our”) is a global leader in customer relationship management (“CRM”) technology, enabling companies of every size and industry to connect with their customers through the power of data, artificial intelligence (“AI”), CRM and trust. Founded in 1999, we bring humans together with AI agents to drive customer success on one deeply unified platform. Our AI-powered Salesforce Platform unites our offerings — spanning sales, service, marketing, commerce, collaboration, integration, AI, analytics, automation, industries and more — by connecting customer data across systems, applications and devices to create a complete view of customers. With this single source of customer truth, teams can be more responsive, productive and efficient and deliver intelligent, personalized and automated experiences across every channel. With Agentforce, the agentic layer of the Salesforce Platform, our customers can build and augment their teams with an always-on digital labor force, deploying autonomous AI agents across business functions that aim to increase productivity, lower costs and drive operational efficiencies. Our service offerings are designed to be flexible, scalable and easy to use. They can generally be configured easily, deployed rapidly and integrated with other platforms and enterprise applications. We sell to businesses worldwide, primarily on a subscription basis, through our direct sales efforts and also indirectly through partners. In addition, we enable third parties to use our platform and developer tools to create additional functionality and new applications that run on our platform, which are sold separately from, or in conjunction with, our service offerings. Salesforce is committed to a core set of values: trust, customer success, innovation, equality and sustainability – all of which are grounded in legal and regulatory frameworks that guide and inform our business. Foremost among these is trust, which is paramount and the foundation for everything we do, and is also firmly rooted in compliance with applicable laws governing security, privacy, data protection and operational integrity. Our customers expect to trust and rely on our technology to meet the high enterprise-grade standards of security, privacy, performance, legal compliance and availability at scale. Customer success is at the core of our business, and we align the entire company around our customers’ needs, promoting their success, showing our value and upholding applicable laws, contractual obligations and industry regulations and standards. Innovation is fundamental to our mission, empowering and enabling our customers to stay ahead in their industries and driving technological advancements in line with evolving laws, standards and guidelines. Equality is a legal and ethical mandate and a core tenet that informs how we operate. Our commitment to equal opportunity is anchored in applicable laws, statutes, regulations and principles. We value the equality of every individual at our company and in our communities and are dedicated to fostering a workplace that complies with these protections, creating an inclusive culture where every individual feels seen, heard and valued. Finally, we are committed to creating a more sustainable and nature-positive future for all. Our products and services help our customers meet their own sustainability and compliance priorities, guided by applicable environmental and sustainability-related laws, corporate social responsibility frameworks and legal requirements. By grounding our values in legal and regulatory principles, we reinforce our opportunity and responsibility to uphold high integrity and robust ethical standards, ensuring that trust, fairness, and compliance remain central to everything we seek to do. We believe that our values, grounded in legal and regulatory frameworks, create value, and the business of business is to make the world a better place for all of our stakeholders, including stockholders, customers, employees, partners, the planet and the communities in which we work and live. Salesforce is committed to giving back to our communities, helping businesses grow while protecting the environment for future generations, and transparent environmental, social and governance disclosures. We believe we have a broad responsibility to society, and we aspire to create a framework for the ethical and humane use of technology that not only drives the success of our customers, but also upholds the basic human rights of every individual. #'],\n",
       "  'reference': 'Salesforce is a global leader in customer relationship management (CRM) technology, enabling companies to connect with their customers through data, artificial intelligence, and trust.',\n",
       "  'synthesizer_name': 'single_hop_specific',\n",
       "  'response': 'Salesforce provides its own Customer Relationship Management (CRM) solutions.',\n",
       "  'retrieved_contexts': ['We believe we have a broad responsibility to society, and we aspire to create a framework for the ethical and humane use of technology that not only drives the success of our customers, but also upholds the basic human rights of every individual.\\n\\n# Our Service Offerings\\n\\nWe believe that every business, in every industry, has to optimize for an AI-first experience for their customers, employees and partners, leveraging trusted AI, data and CRM technology to increase efficiency, boost productivity and drive growth. Through Agentforce, our suite of customizable AI agents and tools, Salesforce brings autonomous AI, unified data and applications together on one deeply unified platform that enables companies of any industry or size to deliver AI-powered, personalized engagement across every customer touchpoint with the ability to hyperscale data and automation.\\n\\nOur service offerings are designed to work together and include:\\n\\nSales. Our Sales offering is an integrated platform that brings together the power of humans with AI agents to help sales teams sell faster and smarter, and to efficiently manage and automate entire sales processes. It provides sales capabilities and tools built for an entire sales organization – across prospecting, sales engagement, team collaboration, sales analytics and AI, sales programs, sales performance, partner management, and revenue and orders. With our Sales offering, businesses can create',\n",
       "   \"# Table of Contents\\n\\n# Technology, Development and Operations\\n\\nWe primarily deliver our solutions as highly scalable cloud computing application and platform services on a multi-tenant technology architecture. Multi-tenancy is an architectural approach that allows us to operate a single application instance for multiple organizations, treating all customers as separate tenants who run in virtual isolation from each other. This approach allows us to spread the cost of delivering our services across our user base and scale our business faster than traditional software vendors while focusing our resources on building new functionality and enhancing existing offerings.\\n\\nWe provide our services through cloud computing platform partners who offer Infrastructure-as-a-Service, including servers, storage, databases and networking, as well as through infrastructure designed and operated by us but secured within third-party data center facilities. We continue to invest and expand the deployment of Hyperforce, which allows our platform and applications to be delivered rapidly and reliably to locations worldwide and provides our customers autonomy and control over data residency.\\n\\nOur technology and product efforts are focused on improving and enhancing the features, functionality, performance, availability and security of our existing service offerings, as well as developing new features, functionality and services. We also remain focused on integrating businesses, services and technologies from acquisitions. Performance, functional depth, security, usability, ease of integration and configuration and sustainability of our solutions influence our technology decisions and product direction.\\n\\n# Competition\\n\\nThe market for our service offerings is highly competitive, rapidly evolving and fragmented, and subject to changing technology with low barriers to entry, shifting customer needs and frequent introductions of new products and services.\\n\\nOur current competitors include:\\n\\n- vendors of packaged business software, as well as companies offering enterprise applications delivered through on-premises offerings from enterprise software application vendors and cloud computing application service providers, either individually or with others;\\n- software companies that provide their product or service free of charge as a single product or when bundled with other offerings, or only charge a premium for advanced features and functionality, as well as companies that offer solutions that are sold without a direct sales organization;\\n- vendors who offer software tailored to specific services, industries or market segments, as opposed to our full suite of service offerings including suppliers of traditional business intelligence and data preparation products, integration software vendors, marketing vendors, e-commerce solutions vendors, or AI software and service vendors;\\n- productivity tool and email providers, unified communications providers and consumer application companies that have entered the business software market; and\\n- traditional platform development environment companies and cloud computing development platform companies who may develop toolsets and products that allow customers to build new applications, including AI augmented applications, that run on the customers’ current infrastructure or as hosted services, as well as would-be customers who may develop enterprise applications for internal use.\\n\\nWe believe more companies may become competitive threats due to the attractiveness of the markets in which we operate. We also expect our competition to change and evolve as we expand into more markets, with new offerings.\\n\\n# Customers\\n\\nWe sell to businesses of all sizes and in almost every industry worldwide. The number of paying subscriptions at each of our customers ranges from one to hundreds of thousands. None of our customers accounted for more than ten percent of our revenues in fiscal years 2025, 2024 or 2023. In addition, we do not have any material dependencies on any specific product, service or particular group or groups.\\n\\n# Customer Service and Support\\n\\nWe offer professional services to help customers achieve business results faster with Salesforce solutions. Our architects and innovation program teams act as advisors to plan and execute digital transformations for our customers. This includes implementation services for multi-offering and complex deployments. We provide best-practices and AI-based recommendations and adoption programs globally. In addition, we provide advanced education, including in-person and online courses, to certify our customers and partners on architecting, administering, deploying and developing our service offerings.\\n\\nOur global customer support group responds to both business and technical inquiries about the use of our products via the web, telephone, email, social networks and other channels. We provide standard customer support during regular business hours to customers as part of our paying subscription editions. We also offer premier customer support that is either included in a premium success offering or sold for an additional fee, which can include services such as priority access to technical resources, developer support and system administration. In addition, we offer a premier priority support add-on that includes proactive monitoring, rapid incident response and instruction from a dedicated support team knowledgeable about the customer's specific.\"]},\n",
       " 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_hop_specific_list[0], len(single_hop_specific_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_hop_specific_eval_dataset = EvaluationDataset.from_list(single_hop_specific_list[:5])\n",
    "len(single_hop_specific_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: . Skipping a sample by assigning it nan score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: . Skipping a sample by assigning it nan score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: . Skipping a sample by assigning it nan score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[17]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 50/50 [06:58<00:00,  8.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nv_accuracy': 1.0000, 'nv_context_relevance': 1.0000, 'nv_response_groundedness': 1.0000, 'answer_correctness': nan, 'answer_relevancy': 0.9526, 'context_precision': 1.0000, 'context_recall': 0.7500, 'faithfulness': nan, 'factual_correctness(mode=f1)': 0.4000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "single_hop_specific_token_text_splitter_result = evaluate(\n",
    "    dataset=single_hop_specific_eval_dataset,\n",
    "    llm=evaluator_llm,\n",
    "    metrics=[\n",
    "        AnswerAccuracy(),\n",
    "        ContextRelevance(),\n",
    "        ResponseGroundedness(), \n",
    "\n",
    "        AnswerCorrectness(),\n",
    "        AnswerRelevancy(), \n",
    "        ContextPrecision(), \n",
    "        ContextRecall(),\n",
    "        Faithfulness(), \n",
    "        FactualCorrectness(), \n",
    "        ResponseRelevancy(),\n",
    "    ],\n",
    "    show_progress=True,\n",
    ")\n",
    "single_hop_specific_token_text_splitter_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nv_accuracy': 1.0000, 'nv_context_relevance': 1.0000, 'nv_response_groundedness': 1.0000, 'answer_correctness': nan, 'answer_relevancy': 0.9526, 'context_precision': 1.0000, 'context_recall': 0.7500, 'faithfulness': nan, 'factual_correctness(mode=f1)': 0.4000}\n"
     ]
    }
   ],
   "source": [
    "pprint(single_hop_specific_token_text_splitter_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_queries(query_engine, test_cases_list):\n",
    "    total_queries = len(test_cases_list)\n",
    "    for test_case in tqdm(test_cases_list, \n",
    "                          desc=\"\\tResponding to queries\",\n",
    "                          total=total_queries,\n",
    "                          unit=\"query\",\n",
    "                          position=0,\n",
    "                          leave=True):\n",
    "        response = query_engine.query(test_case[\"user_input\"])\n",
    "        test_case[\"response\"] = str(response.response)\n",
    "        test_case[\"retrieved_contexts\"] = [node.text for node in response.source_nodes]\n",
    "    \n",
    "    try:\n",
    "        eval_dataset = EvaluationDataset.from_list(test_cases_list)\n",
    "        eval_result = evaluate(\n",
    "            dataset=eval_dataset,\n",
    "            llm=evaluator_llm,\n",
    "            metrics=[\n",
    "                AnswerCorrectness(),\n",
    "                AnswerRelevancy(), \n",
    "                ContextPrecision(), \n",
    "                ContextRecall(),\n",
    "                Faithfulness(), \n",
    "                FactualCorrectness(), \n",
    "                ResponseRelevancy(),\n",
    "            ],\n",
    "            show_progress=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        pass # ignore the exception\n",
    "    # only select the newly added metrics which are of dtype float64\n",
    "    return eval_result.to_pandas().select_dtypes(include=['float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query*engines = {\n",
    "\"token\": token*,\n",
    "\"markdown\": md_query_engine,\n",
    "\"markdown_element\": mde_query_engine,\n",
    "\"semantic\": semantic_query_engine,\n",
    "\"sentwin\": sentwin_query_engine\n",
    "}\n",
    "\n",
    "eval_results = {}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
